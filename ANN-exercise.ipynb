{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing Theano\n",
    "#! pip install theano\n",
    "\n",
    "# Installing Tensorflow\n",
    "#! pip install tensorflow\n",
    "\n",
    "# Installing Keras\n",
    "#! pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>15767821</td>\n",
       "      <td>Bearce</td>\n",
       "      <td>528</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>102016.72</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80181.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>15737173</td>\n",
       "      <td>Andrews</td>\n",
       "      <td>497</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76390.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>15632264</td>\n",
       "      <td>Kay</td>\n",
       "      <td>476</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26260.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15691483</td>\n",
       "      <td>Chin</td>\n",
       "      <td>549</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190857.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>15600882</td>\n",
       "      <td>Scott</td>\n",
       "      <td>635</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65951.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0           1    15634602  Hargrave          619    France  Female   42   \n",
       "1           2    15647311      Hill          608     Spain  Female   41   \n",
       "2           3    15619304      Onio          502    France  Female   42   \n",
       "3           4    15701354      Boni          699    France  Female   39   \n",
       "4           5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5           6    15574012       Chu          645     Spain    Male   44   \n",
       "6           7    15592531  Bartlett          822    France    Male   50   \n",
       "7           8    15656148    Obinna          376   Germany  Female   29   \n",
       "8           9    15792365        He          501    France    Male   44   \n",
       "9          10    15592389        H?          684    France    Male   27   \n",
       "10         11    15767821    Bearce          528    France    Male   31   \n",
       "11         12    15737173   Andrews          497     Spain    Male   24   \n",
       "12         13    15632264       Kay          476    France  Female   34   \n",
       "13         14    15691483      Chin          549    France  Female   25   \n",
       "14         15    15600882     Scott          635     Spain  Female   35   \n",
       "\n",
       "    Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2       0.00              1          1               1   \n",
       "1        1   83807.86              1          0               1   \n",
       "2        8  159660.80              3          1               0   \n",
       "3        1       0.00              2          0               0   \n",
       "4        2  125510.82              1          1               1   \n",
       "5        8  113755.78              2          1               0   \n",
       "6        7       0.00              2          1               1   \n",
       "7        4  115046.74              4          1               0   \n",
       "8        4  142051.07              2          0               1   \n",
       "9        2  134603.88              1          1               1   \n",
       "10       6  102016.72              2          0               0   \n",
       "11       3       0.00              2          1               0   \n",
       "12      10       0.00              2          1               0   \n",
       "13       5       0.00              2          0               0   \n",
       "14       7       0.00              2          1               1   \n",
       "\n",
       "    EstimatedSalary  Exited  \n",
       "0         101348.88       1  \n",
       "1         112542.58       0  \n",
       "2         113931.57       1  \n",
       "3          93826.63       0  \n",
       "4          79084.10       0  \n",
       "5         149756.71       1  \n",
       "6          10062.80       0  \n",
       "7         119346.88       1  \n",
       "8          74940.50       0  \n",
       "9          71725.73       0  \n",
       "10         80181.12       0  \n",
       "11         76390.01       0  \n",
       "12         26260.98       0  \n",
       "13        190857.79       0  \n",
       "14         65951.65       0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      "RowNumber          10000 non-null int64\n",
      "CustomerId         10000 non-null int64\n",
      "Surname            10000 non-null object\n",
      "CreditScore        10000 non-null int64\n",
      "Geography          10000 non-null object\n",
      "Gender             10000 non-null object\n",
      "Age                10000 non-null int64\n",
      "Tenure             10000 non-null int64\n",
      "Balance            10000 non-null float64\n",
      "NumOfProducts      10000 non-null int64\n",
      "HasCrCard          10000 non-null int64\n",
      "IsActiveMember     10000 non-null int64\n",
      "EstimatedSalary    10000 non-null float64\n",
      "Exited             10000 non-null int64\n",
      "dtypes: float64(2), int64(9), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
       "        -1.03227043,  1.10643166],\n",
       "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
       "         0.9687384 , -0.74866447],\n",
       "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
       "        -1.03227043,  1.48533467],\n",
       "       ...,\n",
       "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
       "        -1.03227043,  1.41231994],\n",
       "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
       "         0.9687384 ,  0.84432121],\n",
       "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
       "        -1.03227043,  0.32472465]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Now let's make the ANN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "# from keras.models import Sequential\n",
    "# i dunno the importing library of Sequential from keras.models didn't work \n",
    "from tensorflow.keras import Sequential\n",
    "#from keras.layers import Dense\n",
    "# i dunno the importing library of Dense from keras.models didn't work \n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
    "# using kerenel_intitializer = 'uniform' because we take random WEIGHT (w(x)), close to zero\n",
    "# using activation='relu', we use rectifier function as first and second hidden layer\n",
    "# relu = rectifier function\n",
    "# input_dim=11 because we have 11 variables input (as dependent variables)\n",
    "\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "# we have no add inpu_dim again because that is included before\n",
    "\n",
    "\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "# output unit = 1\n",
    "# using activation = 'sigmoid', because we want to predict probability of customer leave the bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# optimizer is the algorithm that you're gonna use\n",
    "# the optimizer for find the best weight\n",
    "# choose the optimizer for stochastic gradient descent algorithm\n",
    "# the most efficient in stochastic graient descent algorithm is Adam\n",
    "# using binary_entropy because we want probability outcome from 0 until 1 (binary number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 4s 553us/sample - loss: 0.5044 - accuracy: 0.7959\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 4s 446us/sample - loss: 0.4301 - accuracy: 0.7960\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 4s 481us/sample - loss: 0.4252 - accuracy: 0.7960\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 3s 404us/sample - loss: 0.4217 - accuracy: 0.7960\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 4s 443us/sample - loss: 0.4183 - accuracy: 0.8171\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 4s 518us/sample - loss: 0.4164 - accuracy: 0.8266\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 3s 391us/sample - loss: 0.4147 - accuracy: 0.8288\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 3s 321us/sample - loss: 0.4132 - accuracy: 0.8295\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 3s 430us/sample - loss: 0.4124 - accuracy: 0.8303\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 4s 458us/sample - loss: 0.4111 - accuracy: 0.8317\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 4s 483us/sample - loss: 0.4102 - accuracy: 0.8325\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 4s 450us/sample - loss: 0.4096 - accuracy: 0.8335\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 4s 468us/sample - loss: 0.4089 - accuracy: 0.8329\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 4s 445us/sample - loss: 0.4088 - accuracy: 0.8331\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 4s 449us/sample - loss: 0.4083 - accuracy: 0.8332\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 4s 512us/sample - loss: 0.4076 - accuracy: 0.8341\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 4s 491us/sample - loss: 0.4071 - accuracy: 0.8339\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 4s 497us/sample - loss: 0.4069 - accuracy: 0.8342\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 4s 496us/sample - loss: 0.4065 - accuracy: 0.8339\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 3s 400us/sample - loss: 0.4063 - accuracy: 0.8347\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 4s 485us/sample - loss: 0.4059 - accuracy: 0.8349\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 3s 380us/sample - loss: 0.4055 - accuracy: 0.8336\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 3s 431us/sample - loss: 0.4053 - accuracy: 0.8341\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 4s 503us/sample - loss: 0.4051 - accuracy: 0.8342\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 4s 490us/sample - loss: 0.4044 - accuracy: 0.8342\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 4s 505us/sample - loss: 0.4038 - accuracy: 0.8349\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 4s 499us/sample - loss: 0.4031 - accuracy: 0.8332\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 4s 499us/sample - loss: 0.4025 - accuracy: 0.8342\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 4s 505us/sample - loss: 0.4024 - accuracy: 0.8346\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 3s 399us/sample - loss: 0.4021 - accuracy: 0.8341\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 4s 501us/sample - loss: 0.4016 - accuracy: 0.8344\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 4s 490us/sample - loss: 0.4007 - accuracy: 0.8346\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 4s 482us/sample - loss: 0.4007 - accuracy: 0.8360\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 4s 495us/sample - loss: 0.4003 - accuracy: 0.8347\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 4s 517us/sample - loss: 0.3999 - accuracy: 0.8353\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 4s 473us/sample - loss: 0.3998 - accuracy: 0.8339 - loss: 0.3986 - accuracy\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 4s 524us/sample - loss: 0.3994 - accuracy: 0.8356\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 4s 471us/sample - loss: 0.3994 - accuracy: 0.8350\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 4s 507us/sample - loss: 0.3988 - accuracy: 0.8359\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 4s 524us/sample - loss: 0.3990 - accuracy: 0.8332\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 4s 480us/sample - loss: 0.3985 - accuracy: 0.8357\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 3s 370us/sample - loss: 0.3986 - accuracy: 0.8350\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 4s 488us/sample - loss: 0.3985 - accuracy: 0.8351\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 4s 493us/sample - loss: 0.3979 - accuracy: 0.8349\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 2s 254us/sample - loss: 0.3979 - accuracy: 0.8340\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 4s 465us/sample - loss: 0.3978 - accuracy: 0.8354\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 4s 500us/sample - loss: 0.3975 - accuracy: 0.8354\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 4s 506us/sample - loss: 0.3971 - accuracy: 0.8351\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 4s 522us/sample - loss: 0.3974 - accuracy: 0.8344\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 4s 481us/sample - loss: 0.3968 - accuracy: 0.8342\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 4s 473us/sample - loss: 0.3972 - accuracy: 0.8341\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 4s 507us/sample - loss: 0.3967 - accuracy: 0.8363\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 4s 489us/sample - loss: 0.3964 - accuracy: 0.8359\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 2s 275us/sample - loss: 0.3961 - accuracy: 0.8347\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 4s 448us/sample - loss: 0.3962 - accuracy: 0.8366\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 4s 490us/sample - loss: 0.3954 - accuracy: 0.8363\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 4s 494us/sample - loss: 0.3957 - accuracy: 0.8340\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 4s 499us/sample - loss: 0.3948 - accuracy: 0.8360\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 4s 500us/sample - loss: 0.3948 - accuracy: 0.8360\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 4s 517us/sample - loss: 0.3947 - accuracy: 0.8356\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 4s 470us/sample - loss: 0.3943 - accuracy: 0.8353\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 4s 498us/sample - loss: 0.3933 - accuracy: 0.8384\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 4s 472us/sample - loss: 0.3927 - accuracy: 0.8381\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 3s 419us/sample - loss: 0.3915 - accuracy: 0.8391\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 4s 483us/sample - loss: 0.3907 - accuracy: 0.8400\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 2s 310us/sample - loss: 0.3894 - accuracy: 0.8374\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 4s 474us/sample - loss: 0.3868 - accuracy: 0.8395 - loss: 0.3846 \n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 4s 475us/sample - loss: 0.3853 - accuracy: 0.8394\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 4s 488us/sample - loss: 0.3812 - accuracy: 0.8407\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 3s 314us/sample - loss: 0.3784 - accuracy: 0.8422\n",
      "Epoch 71/100\n",
      "8000/8000 [==============================] - 4s 494us/sample - loss: 0.3763 - accuracy: 0.8403\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 4s 451us/sample - loss: 0.3740 - accuracy: 0.8413\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 4s 472us/sample - loss: 0.3722 - accuracy: 0.8414\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 4s 469us/sample - loss: 0.3706 - accuracy: 0.8425\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 4s 470us/sample - loss: 0.3686 - accuracy: 0.8446\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 3s 413us/sample - loss: 0.3673 - accuracy: 0.8444\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 3s 399us/sample - loss: 0.3659 - accuracy: 0.8451\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 3s 367us/sample - loss: 0.3636 - accuracy: 0.8482\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 2s 243us/sample - loss: 0.3620 - accuracy: 0.8503\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 2s 247us/sample - loss: 0.3608 - accuracy: 0.8493\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 2s 245us/sample - loss: 0.3586 - accuracy: 0.8526\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 2s 246us/sample - loss: 0.3531 - accuracy: 0.8558 - loss: 0.3538 - accuracy: 0.\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 2s 268us/sample - loss: 0.3493 - accuracy: 0.8587\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 3s 394us/sample - loss: 0.3469 - accuracy: 0.8580\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 4s 488us/sample - loss: 0.3445 - accuracy: 0.8597\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 4s 525us/sample - loss: 0.3435 - accuracy: 0.8600\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 3s 421us/sample - loss: 0.3431 - accuracy: 0.8606\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 3s 431us/sample - loss: 0.3430 - accuracy: 0.8627\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 3s 418us/sample - loss: 0.3421 - accuracy: 0.8605\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 4s 489us/sample - loss: 0.3413 - accuracy: 0.8609\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 4s 506us/sample - loss: 0.3419 - accuracy: 0.8593\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 4s 502us/sample - loss: 0.3414 - accuracy: 0.8601\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 3s 366us/sample - loss: 0.3409 - accuracy: 0.8605\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 3s 382us/sample - loss: 0.3415 - accuracy: 0.8601\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 3s 417us/sample - loss: 0.3409 - accuracy: 0.8618\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 4s 530us/sample - loss: 0.3405 - accuracy: 0.8602\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 3s 435us/sample - loss: 0.3398 - accuracy: 0.8633\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 3s 429us/sample - loss: 0.3402 - accuracy: 0.8616\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 4s 495us/sample - loss: 0.3401 - accuracy: 0.8602\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 4s 536us/sample - loss: 0.3396 - accuracy: 0.8615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208a916ccc8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Change value of y_pred. If y_pred > 0.5 that would be 'True', and if y_pred <= 0.5 would be 'False'\n",
    "# 0.5 is the threshold you can choose from 0 until 1. \n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# example : y_pred =0.2 -> it is mean that the customer has 20% probability to leave the bank (churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1517,   78],\n",
       "       [ 197,  208]], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our ANN model to predict if the customer with the following informations will leave the bank:Â \n",
    "- Geography: France\n",
    "- Credit Score: 600\n",
    "- Gender: Male\n",
    "- Age: 40 years old\n",
    "- Tenure: 3 years\n",
    "- Balance: USD 60000\n",
    "- Number of Products: 2\n",
    "- Does this customer have a credit card ?Â Yes\n",
    "- Is this customer an Active Member: Yes\n",
    "- Estimated Salary: USD 50000\n",
    "- So should we say goodbye to that customer ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Table ()\n",
    "t['CreditScore']=[600]\n",
    "t['Geography']=['France']\n",
    "t['Gender']='Male'\n",
    "t['Age']=40\n",
    "t['Tenure']=3\n",
    "t['Balance']=60000\n",
    "t['NumOfProducts']=2\n",
    "t['HasCrCard']=1\n",
    "t['IsActiveMember']=1\n",
    "t['EstimatedSalary']=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>Table length=1</i>\n",
       "<table id=\"table2236905225416\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>CreditScore</th><th>Geography</th><th>Gender</th><th>Age</th><th>Tenure</th><th>Balance</th><th>NumOfProducts</th><th>HasCrCard</th><th>IsActiveMember</th><th>EstimatedSalary</th></tr></thead>\n",
       "<thead><tr><th>int32</th><th>str6</th><th>str4</th><th>int32</th><th>int32</th><th>int32</th><th>int32</th><th>int32</th><th>int32</th><th>int32</th></tr></thead>\n",
       "<tr><td>600</td><td>France</td><td>Male</td><td>40</td><td>3</td><td>60000</td><td>2</td><td>1</td><td>1</td><td>50000</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=1>\n",
       "CreditScore Geography Gender  Age  ... HasCrCard IsActiveMember EstimatedSalary\n",
       "   int32       str6    str4  int32 ...   int32       int32           int32     \n",
       "----------- --------- ------ ----- ... --------- -------------- ---------------\n",
       "        600    France   Male    40 ...         1              1           50000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_prediction = classifier.predict(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "new_prediction = (new_prediction > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=new_prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye our beloved Customer\n"
     ]
    }
   ],
   "source": [
    "if (a == False) :\n",
    "    print ('Goodbye our beloved Customer')\n",
    "elif (a == True) :\n",
    "    print ('We have many more good service. Would you hear it from us?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5 - Evaluating ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find it in the note book named : Evaluating ANN-exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
