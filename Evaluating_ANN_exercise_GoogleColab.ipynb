{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Evaluating_ANN_exercise_GoogleColab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wElkRsDco3Fq"
      },
      "source": [
        "# Artificial Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_3rt4sb9o3Fy"
      },
      "source": [
        "### Installing Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pFsV7L0wo3F1",
        "outputId": "9c18fb4e-aab2-45c3-f78a-540770b26474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "# Installing Theano\n",
        "! pip install theano\n",
        "\n",
        "# Installing Tensorflow\n",
        "! pip install tensorflow\n",
        "\n",
        "# Installing Keras\n",
        "! pip install keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from theano) (1.17.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from theano) (1.3.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (41.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TV-w-PLso3F9"
      },
      "source": [
        "# Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IaA0NfIo3F-",
        "colab": {}
      },
      "source": [
        "# Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B6V7_nN9o3GD",
        "colab": {}
      },
      "source": [
        "# Importing the dataset\n",
        "dataset = pd.read_csv('Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:13].values\n",
        "y = dataset.iloc[:, 13].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lf0MuMzNo3GH",
        "outputId": "09813030-27d0-49b3-cb6e-b43e359c7584",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        }
      },
      "source": [
        "dataset.head(15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>15574012</td>\n",
              "      <td>Chu</td>\n",
              "      <td>645</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>8</td>\n",
              "      <td>113755.78</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>149756.71</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>15592531</td>\n",
              "      <td>Bartlett</td>\n",
              "      <td>822</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>50</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10062.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>15656148</td>\n",
              "      <td>Obinna</td>\n",
              "      <td>376</td>\n",
              "      <td>Germany</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>115046.74</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119346.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>15792365</td>\n",
              "      <td>He</td>\n",
              "      <td>501</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>142051.07</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>74940.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>15592389</td>\n",
              "      <td>H?</td>\n",
              "      <td>684</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>27</td>\n",
              "      <td>2</td>\n",
              "      <td>134603.88</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>71725.73</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>15767821</td>\n",
              "      <td>Bearce</td>\n",
              "      <td>528</td>\n",
              "      <td>France</td>\n",
              "      <td>Male</td>\n",
              "      <td>31</td>\n",
              "      <td>6</td>\n",
              "      <td>102016.72</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80181.12</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>15737173</td>\n",
              "      <td>Andrews</td>\n",
              "      <td>497</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Male</td>\n",
              "      <td>24</td>\n",
              "      <td>3</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>76390.01</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>15632264</td>\n",
              "      <td>Kay</td>\n",
              "      <td>476</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>34</td>\n",
              "      <td>10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>26260.98</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>15691483</td>\n",
              "      <td>Chin</td>\n",
              "      <td>549</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>190857.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>15600882</td>\n",
              "      <td>Scott</td>\n",
              "      <td>635</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>65951.65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    RowNumber  CustomerId   Surname  ...  IsActiveMember EstimatedSalary Exited\n",
              "0           1    15634602  Hargrave  ...               1       101348.88      1\n",
              "1           2    15647311      Hill  ...               1       112542.58      0\n",
              "2           3    15619304      Onio  ...               0       113931.57      1\n",
              "3           4    15701354      Boni  ...               0        93826.63      0\n",
              "4           5    15737888  Mitchell  ...               1        79084.10      0\n",
              "5           6    15574012       Chu  ...               0       149756.71      1\n",
              "6           7    15592531  Bartlett  ...               1        10062.80      0\n",
              "7           8    15656148    Obinna  ...               0       119346.88      1\n",
              "8           9    15792365        He  ...               1        74940.50      0\n",
              "9          10    15592389        H?  ...               1        71725.73      0\n",
              "10         11    15767821    Bearce  ...               0        80181.12      0\n",
              "11         12    15737173   Andrews  ...               0        76390.01      0\n",
              "12         13    15632264       Kay  ...               0        26260.98      0\n",
              "13         14    15691483      Chin  ...               0       190857.79      0\n",
              "14         15    15600882     Scott  ...               1        65951.65      0\n",
              "\n",
              "[15 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B7eVdZ-0o3GM",
        "outputId": "8322fed9-9393-4364-e6c0-afa68812d2cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        }
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 14 columns):\n",
            "RowNumber          10000 non-null int64\n",
            "CustomerId         10000 non-null int64\n",
            "Surname            10000 non-null object\n",
            "CreditScore        10000 non-null int64\n",
            "Geography          10000 non-null object\n",
            "Gender             10000 non-null object\n",
            "Age                10000 non-null int64\n",
            "Tenure             10000 non-null int64\n",
            "Balance            10000 non-null float64\n",
            "NumOfProducts      10000 non-null int64\n",
            "HasCrCard          10000 non-null int64\n",
            "IsActiveMember     10000 non-null int64\n",
            "EstimatedSalary    10000 non-null float64\n",
            "Exited             10000 non-null int64\n",
            "dtypes: float64(2), int64(9), object(3)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JeozNZ2bo3GQ",
        "outputId": "e64a5daa-3f49-4f21-c514-8814182292be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "# Encoding categorical data\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "labelencoder_X_1 = LabelEncoder()\n",
        "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
        "labelencoder_X_2 = LabelEncoder()\n",
        "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
        "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
        "X = onehotencoder.fit_transform(X).toarray()\n",
        "X = X[:, 1:]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:451: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
            "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Raorkw12o3GU",
        "colab": {}
      },
      "source": [
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jAaZR0_uo3GX",
        "colab": {}
      },
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Op8S-jlo3Ga",
        "outputId": "e95513a1-59bb-4a4c-db15-f079ddd04353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "X_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.5698444 ,  1.74309049,  0.16958176, ...,  0.64259497,\n",
              "        -1.03227043,  1.10643166],\n",
              "       [ 1.75486502, -0.57369368, -2.30455945, ...,  0.64259497,\n",
              "         0.9687384 , -0.74866447],\n",
              "       [-0.5698444 , -0.57369368, -1.19119591, ...,  0.64259497,\n",
              "        -1.03227043,  1.48533467],\n",
              "       ...,\n",
              "       [-0.5698444 , -0.57369368,  0.9015152 , ...,  0.64259497,\n",
              "        -1.03227043,  1.41231994],\n",
              "       [-0.5698444 ,  1.74309049, -0.62420521, ...,  0.64259497,\n",
              "         0.9687384 ,  0.84432121],\n",
              "       [ 1.75486502, -0.57369368, -0.28401079, ...,  0.64259497,\n",
              "        -1.03227043,  0.32472465]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rYTqT9-co3Gd"
      },
      "source": [
        "# Part 5 - Evaluating ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iRJ3qxHeo3Gd",
        "outputId": "32896102-e27e-4f60-8e2e-f07eb0f54f15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "source": [
        "# Importing the Keras libraries and packages\n",
        "#import keras\n",
        "#from keras.models import Sequential\n",
        "#from tensorflow.keras import Sequential\n",
        "#from keras.layers import Dense\n",
        "#from tensorflow.keras.layers import Dense\n",
        "#print('\\n -------------------libraries 1 are imported---------------------\\n')\n",
        "#-------------------------------------------------\n",
        "\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "#from tensorflow.keras import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "print('\\n -------------------libraries 2 are imported---------------------\\n')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " -------------------libraries 2 are imported---------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rpxb6JZpt1Mj",
        "outputId": "31e498a1-80d2-484b-9f85-efae8a8ca614",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# update tensorflow\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V4Egf6UJo3Gg",
        "colab": {}
      },
      "source": [
        "def build_classifier():\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier, batch_size = 10, epochs = 100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1wkhf4Xto3Gi",
        "outputId": "d73739a6-d3d1-4e52-fa5b-ee12dd78b0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10, n_jobs = -1)\n",
        "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
        "mean = accuracies.mean()\n",
        "variance = accuracies.std()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7200/7200 [==============================] - 2s 242us/step - loss: 0.4906 - acc: 0.7957\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4284 - acc: 0.7971\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4239 - acc: 0.7971\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4198 - acc: 0.8069\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4171 - acc: 0.8243\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4153 - acc: 0.8276\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4136 - acc: 0.8287\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4125 - acc: 0.8303\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4119 - acc: 0.8308\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4104 - acc: 0.8332\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4097 - acc: 0.8331\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4088 - acc: 0.8325\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4078 - acc: 0.8332\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4076 - acc: 0.8347\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4072 - acc: 0.8332\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4068 - acc: 0.8342\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4062 - acc: 0.8349\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4059 - acc: 0.8351\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4056 - acc: 0.8342\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4052 - acc: 0.8347\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4049 - acc: 0.8347\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4049 - acc: 0.8346\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4044 - acc: 0.8357\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4043 - acc: 0.8346\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4041 - acc: 0.8350\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4037 - acc: 0.8353\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4036 - acc: 0.8376\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4035 - acc: 0.8353\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4030 - acc: 0.8354\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4031 - acc: 0.8335\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4028 - acc: 0.8357\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4031 - acc: 0.8349\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4030 - acc: 0.8353\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4022 - acc: 0.8342\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4024 - acc: 0.8362\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4023 - acc: 0.8342\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4021 - acc: 0.8356\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4020 - acc: 0.8356\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4026 - acc: 0.8356\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4016 - acc: 0.8346\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4016 - acc: 0.8351\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4019 - acc: 0.8349\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4018 - acc: 0.8335\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4018 - acc: 0.8337\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4016 - acc: 0.8343\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4017 - acc: 0.8343\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4017 - acc: 0.8353\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4014 - acc: 0.8349\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4018 - acc: 0.8337\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4011 - acc: 0.8360\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4009 - acc: 0.8346\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4010 - acc: 0.8356\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4013 - acc: 0.8343\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4014 - acc: 0.8347\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4009 - acc: 0.8342\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4010 - acc: 0.8353\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4007 - acc: 0.8358\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4011 - acc: 0.8357\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.4001 - acc: 0.8342\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 157us/step - loss: 0.4012 - acc: 0.8344\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.4005 - acc: 0.8350\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4006 - acc: 0.8339\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4004 - acc: 0.8360\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4007 - acc: 0.8349\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4008 - acc: 0.8337\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4004 - acc: 0.8340\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4003 - acc: 0.8347\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4005 - acc: 0.8339\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4005 - acc: 0.8344\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4004 - acc: 0.8342\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4002 - acc: 0.8351\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4003 - acc: 0.8328\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3999 - acc: 0.8336\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4002 - acc: 0.8335\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3997 - acc: 0.8360\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4000 - acc: 0.8347\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3995 - acc: 0.8337\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3996 - acc: 0.8347\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3994 - acc: 0.8343\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3994 - acc: 0.8351\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3993 - acc: 0.8344\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3987 - acc: 0.8351\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3986 - acc: 0.8360\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3988 - acc: 0.8353\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3985 - acc: 0.8328\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3986 - acc: 0.8353\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3974 - acc: 0.8349\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3973 - acc: 0.8354\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3972 - acc: 0.8346\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3967 - acc: 0.8350\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3968 - acc: 0.8362\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3964 - acc: 0.8342\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3963 - acc: 0.8354\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3951 - acc: 0.8353\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3951 - acc: 0.8378\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3946 - acc: 0.8365\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3950 - acc: 0.8357\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3946 - acc: 0.8375\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3943 - acc: 0.8367\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3935 - acc: 0.8360\n",
            "800/800 [==============================] - 0s 99us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 161us/step - loss: 0.4899 - acc: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4275 - acc: 0.7967\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4224 - acc: 0.7967\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4184 - acc: 0.8183\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4176 - acc: 0.8228\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4156 - acc: 0.8275\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4142 - acc: 0.8282\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4129 - acc: 0.8304\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4121 - acc: 0.8300\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4111 - acc: 0.8312\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4106 - acc: 0.8317\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4101 - acc: 0.8311\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4090 - acc: 0.8328\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4089 - acc: 0.8337\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4085 - acc: 0.8343\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4082 - acc: 0.8349\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4074 - acc: 0.8342\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4071 - acc: 0.8329\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 119us/step - loss: 0.4073 - acc: 0.8333\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4068 - acc: 0.8326\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4047 - acc: 0.8318\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4060 - acc: 0.8335\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4059 - acc: 0.8346\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4056 - acc: 0.8324\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4059 - acc: 0.8349\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4049 - acc: 0.8336\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4046 - acc: 0.8347\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4050 - acc: 0.8342\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4046 - acc: 0.8349\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4045 - acc: 0.8342\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4040 - acc: 0.8337\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4043 - acc: 0.8335\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4035 - acc: 0.8351\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4036 - acc: 0.8340\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4036 - acc: 0.8354\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4038 - acc: 0.8346\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4037 - acc: 0.8339\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4031 - acc: 0.8329\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4027 - acc: 0.8362\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4032 - acc: 0.8326\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4029 - acc: 0.8349\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4032 - acc: 0.8331\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4026 - acc: 0.8358\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4025 - acc: 0.8335\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4026 - acc: 0.8326\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4024 - acc: 0.8342\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4021 - acc: 0.8346\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4022 - acc: 0.8331\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4023 - acc: 0.8346\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4022 - acc: 0.8335\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4019 - acc: 0.8339\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4016 - acc: 0.8336\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4019 - acc: 0.8342\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4019 - acc: 0.8339\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4019 - acc: 0.8339\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4017 - acc: 0.8346\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4019 - acc: 0.8365\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4016 - acc: 0.8335\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4010 - acc: 0.8364\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4014 - acc: 0.8329\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4013 - acc: 0.8353\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4010 - acc: 0.8329\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4019 - acc: 0.8329\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4008 - acc: 0.8357\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4014 - acc: 0.8364\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4014 - acc: 0.8340\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4013 - acc: 0.8353\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4012 - acc: 0.8346\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4012 - acc: 0.8356\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4013 - acc: 0.8342\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4013 - acc: 0.8346\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4011 - acc: 0.8346\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4007 - acc: 0.8346\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4012 - acc: 0.8347\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4005 - acc: 0.8346\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4008 - acc: 0.8342\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4008 - acc: 0.8344\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4006 - acc: 0.8343\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4007 - acc: 0.8350\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4001 - acc: 0.8343\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3999 - acc: 0.8361\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4010 - acc: 0.8358\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4003 - acc: 0.8356\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.4006 - acc: 0.8343\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4003 - acc: 0.8349\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3999 - acc: 0.8360\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4002 - acc: 0.8322\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 121us/step - loss: 0.4003 - acc: 0.8331\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3999 - acc: 0.8344\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4003 - acc: 0.8346\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4005 - acc: 0.8358\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3998 - acc: 0.8357\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4002 - acc: 0.8356\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.3994 - acc: 0.8351\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 122us/step - loss: 0.3999 - acc: 0.8360\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4000 - acc: 0.8347\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3998 - acc: 0.8328\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4007 - acc: 0.8354\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3995 - acc: 0.8336\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 123us/step - loss: 0.4001 - acc: 0.8337\n",
            "800/800 [==============================] - 0s 114us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 166us/step - loss: 0.4909 - acc: 0.7949\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4301 - acc: 0.7956\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4256 - acc: 0.7956\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4216 - acc: 0.8147\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4191 - acc: 0.8242\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4166 - acc: 0.8296\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4152 - acc: 0.8303\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4139 - acc: 0.8312\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4130 - acc: 0.8336\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4118 - acc: 0.8337\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4112 - acc: 0.8332\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4099 - acc: 0.8335\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4095 - acc: 0.8332\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4087 - acc: 0.8347\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4086 - acc: 0.8339\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4073 - acc: 0.8343\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4071 - acc: 0.8333\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4063 - acc: 0.8357\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4063 - acc: 0.8354\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4058 - acc: 0.8333\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4050 - acc: 0.8350\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4040 - acc: 0.8364\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4048 - acc: 0.8350\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4045 - acc: 0.8353\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4041 - acc: 0.8337\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4039 - acc: 0.8340\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4035 - acc: 0.8353\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4030 - acc: 0.8349\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4033 - acc: 0.8342\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4027 - acc: 0.8351\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4032 - acc: 0.8339\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4028 - acc: 0.8340\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4029 - acc: 0.8358\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4022 - acc: 0.8349\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4025 - acc: 0.8336\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4026 - acc: 0.8357\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4024 - acc: 0.8361\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4028 - acc: 0.8353\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4020 - acc: 0.8331\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4026 - acc: 0.8343\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4020 - acc: 0.8365\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4016 - acc: 0.8350\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4020 - acc: 0.8357\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4017 - acc: 0.8383\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4017 - acc: 0.8353\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4019 - acc: 0.8357\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4011 - acc: 0.8356\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4013 - acc: 0.8351\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4015 - acc: 0.8369\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4012 - acc: 0.8336\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4013 - acc: 0.8353\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4013 - acc: 0.8358\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4010 - acc: 0.8351\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4011 - acc: 0.8372\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4010 - acc: 0.8368\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4009 - acc: 0.8347\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4011 - acc: 0.8361\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4005 - acc: 0.8369\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4006 - acc: 0.8365\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4009 - acc: 0.8369\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4006 - acc: 0.8360\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4010 - acc: 0.8340\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4006 - acc: 0.8351\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4008 - acc: 0.8371\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.4004 - acc: 0.8371\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4009 - acc: 0.8353\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4007 - acc: 0.8374\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4004 - acc: 0.8358\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4011 - acc: 0.8368\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4005 - acc: 0.8369\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4006 - acc: 0.8358\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4004 - acc: 0.8347\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4003 - acc: 0.8358\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4009 - acc: 0.8356\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.4009 - acc: 0.8351\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4005 - acc: 0.8375\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4006 - acc: 0.8350\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4002 - acc: 0.8368\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4000 - acc: 0.8371\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4004 - acc: 0.8349\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4000 - acc: 0.8371\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4009 - acc: 0.8346\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3998 - acc: 0.8360\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4004 - acc: 0.8374\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4002 - acc: 0.8382\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4002 - acc: 0.8360\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4001 - acc: 0.8362\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4004 - acc: 0.8367\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4002 - acc: 0.8362\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4004 - acc: 0.8344\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3996 - acc: 0.8364\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4001 - acc: 0.8374\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4006 - acc: 0.8361\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4001 - acc: 0.8344\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4002 - acc: 0.8361\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4006 - acc: 0.8354\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4006 - acc: 0.8372\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4001 - acc: 0.8365\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4000 - acc: 0.8360\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4003 - acc: 0.8365\n",
            "800/800 [==============================] - 0s 137us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 180us/step - loss: 0.5094 - acc: 0.8026\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4077 - acc: 0.8211\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3961 - acc: 0.8282\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3888 - acc: 0.8292\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3829 - acc: 0.8321\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3789 - acc: 0.8300\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3766 - acc: 0.8321\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3731 - acc: 0.8339\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3710 - acc: 0.8425\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3693 - acc: 0.8472\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3658 - acc: 0.8510\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3640 - acc: 0.8494\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3614 - acc: 0.8512\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3593 - acc: 0.8515\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3581 - acc: 0.8536\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3564 - acc: 0.8567\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3553 - acc: 0.8547\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3537 - acc: 0.8561\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3520 - acc: 0.8551\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3507 - acc: 0.8560\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3504 - acc: 0.8536\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3495 - acc: 0.8544\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3487 - acc: 0.8544\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3468 - acc: 0.8574\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3454 - acc: 0.8569\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3454 - acc: 0.8569\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3447 - acc: 0.8578\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3437 - acc: 0.8582\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3432 - acc: 0.8594\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3435 - acc: 0.8579\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3405 - acc: 0.8587\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3417 - acc: 0.8587\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3421 - acc: 0.8568\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3403 - acc: 0.8587\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3405 - acc: 0.8606\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3416 - acc: 0.8603\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3409 - acc: 0.8599\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3402 - acc: 0.8590\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3394 - acc: 0.8603\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3391 - acc: 0.8592\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3382 - acc: 0.8592\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3391 - acc: 0.8601\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3381 - acc: 0.8618\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3388 - acc: 0.8589\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3391 - acc: 0.8604\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3383 - acc: 0.8590\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3368 - acc: 0.8592\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3381 - acc: 0.8614\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3377 - acc: 0.8599\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3378 - acc: 0.8585\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3374 - acc: 0.8597\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3378 - acc: 0.8596\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3371 - acc: 0.8614\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3369 - acc: 0.8611\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3373 - acc: 0.8618\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 125us/step - loss: 0.3365 - acc: 0.8607\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3360 - acc: 0.8589\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3364 - acc: 0.8596\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3364 - acc: 0.8618\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3356 - acc: 0.8614\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3363 - acc: 0.8599\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3366 - acc: 0.8578\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3368 - acc: 0.8603\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3354 - acc: 0.8615\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3346 - acc: 0.8594\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3356 - acc: 0.8597\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3354 - acc: 0.8607\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 124us/step - loss: 0.3355 - acc: 0.8621\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3345 - acc: 0.8619\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3359 - acc: 0.8594\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3354 - acc: 0.8594\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3348 - acc: 0.8592\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3337 - acc: 0.8625\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3341 - acc: 0.8617\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3343 - acc: 0.8611\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3333 - acc: 0.8619\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3348 - acc: 0.8629\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3338 - acc: 0.8606\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3336 - acc: 0.8612\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3345 - acc: 0.8603\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3346 - acc: 0.8604\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3327 - acc: 0.8593\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3340 - acc: 0.8608\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3337 - acc: 0.8603\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3333 - acc: 0.8585\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3333 - acc: 0.8607\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3341 - acc: 0.8608\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3325 - acc: 0.8619\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3334 - acc: 0.8626\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3330 - acc: 0.8586\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3323 - acc: 0.8601\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3323 - acc: 0.8635\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3320 - acc: 0.8625\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3333 - acc: 0.8624\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3328 - acc: 0.8610\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3323 - acc: 0.8599\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3328 - acc: 0.8625\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3331 - acc: 0.8604\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3333 - acc: 0.8611\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3337 - acc: 0.8628\n",
            "800/800 [==============================] - 0s 168us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 189us/step - loss: 0.5066 - acc: 0.7926\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4334 - acc: 0.7937\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4288 - acc: 0.7937\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4251 - acc: 0.7937\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4222 - acc: 0.8117\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4204 - acc: 0.8221\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4186 - acc: 0.8233\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4171 - acc: 0.8276\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4161 - acc: 0.8283\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4149 - acc: 0.8311\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4141 - acc: 0.8315\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4129 - acc: 0.8315\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4125 - acc: 0.8312\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4120 - acc: 0.8324\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4111 - acc: 0.8326\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4108 - acc: 0.8335\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4106 - acc: 0.8326\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4100 - acc: 0.8331\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4098 - acc: 0.8329\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4093 - acc: 0.8331\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4094 - acc: 0.8329\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4090 - acc: 0.8331\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4088 - acc: 0.8331\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4084 - acc: 0.8335\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4080 - acc: 0.8331\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4082 - acc: 0.8340\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4075 - acc: 0.8332\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4074 - acc: 0.8331\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4070 - acc: 0.8325\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4072 - acc: 0.8346\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4067 - acc: 0.8344\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4066 - acc: 0.8337\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4067 - acc: 0.8331\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4065 - acc: 0.8339\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4066 - acc: 0.8328\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4061 - acc: 0.8339\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4063 - acc: 0.8344\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4063 - acc: 0.8343\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4063 - acc: 0.8329\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4061 - acc: 0.8326\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4060 - acc: 0.8344\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4058 - acc: 0.8337\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4057 - acc: 0.8324\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4055 - acc: 0.8333\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4058 - acc: 0.8332\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4056 - acc: 0.8324\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4053 - acc: 0.8325\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4057 - acc: 0.8322\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4056 - acc: 0.8318\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4056 - acc: 0.8340\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4055 - acc: 0.8342\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4055 - acc: 0.8322\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4053 - acc: 0.8325\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4055 - acc: 0.8317\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4050 - acc: 0.8335\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4049 - acc: 0.8326\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4050 - acc: 0.8335\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4053 - acc: 0.8340\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4048 - acc: 0.8335\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4050 - acc: 0.8317\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4049 - acc: 0.8326\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4049 - acc: 0.8321\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4048 - acc: 0.8342\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.4044 - acc: 0.8326\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4037 - acc: 0.8311\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4041 - acc: 0.8331\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4037 - acc: 0.8343\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4031 - acc: 0.8333\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4035 - acc: 0.8339\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4029 - acc: 0.8342\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4027 - acc: 0.8321\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4027 - acc: 0.8321\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4021 - acc: 0.8321\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4023 - acc: 0.8315\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4016 - acc: 0.8326\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4019 - acc: 0.8332\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4016 - acc: 0.8340\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4018 - acc: 0.8324\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4009 - acc: 0.8326\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4011 - acc: 0.8351\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4011 - acc: 0.8335\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.4004 - acc: 0.8329\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4006 - acc: 0.8340\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.4004 - acc: 0.8331\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4003 - acc: 0.8344\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4000 - acc: 0.8342\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4002 - acc: 0.8347\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3994 - acc: 0.8351\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4005 - acc: 0.8331\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4000 - acc: 0.8346\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3994 - acc: 0.8331\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3999 - acc: 0.8343\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3991 - acc: 0.8343\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3991 - acc: 0.8347\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3996 - acc: 0.8353\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3993 - acc: 0.8346\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3992 - acc: 0.8342\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3986 - acc: 0.8333\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3992 - acc: 0.8344\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.3989 - acc: 0.8335\n",
            "800/800 [==============================] - 0s 191us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 224us/step - loss: 0.4897 - acc: 0.7944\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4282 - acc: 0.7944\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4209 - acc: 0.8147\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4154 - acc: 0.8286\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4113 - acc: 0.8301\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4080 - acc: 0.8331\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4057 - acc: 0.8350\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4041 - acc: 0.8342\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4036 - acc: 0.8339\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4022 - acc: 0.8329\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4008 - acc: 0.8343\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4005 - acc: 0.8351\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3995 - acc: 0.8361\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3985 - acc: 0.8337\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3986 - acc: 0.8344\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3982 - acc: 0.8365\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3977 - acc: 0.8364\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3970 - acc: 0.8364\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3968 - acc: 0.8354\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3964 - acc: 0.8360\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3960 - acc: 0.8365\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3960 - acc: 0.8369\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3964 - acc: 0.8354\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3953 - acc: 0.8364\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3962 - acc: 0.8354\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3955 - acc: 0.8371\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3952 - acc: 0.8351\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3953 - acc: 0.8356\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3948 - acc: 0.8387\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3948 - acc: 0.8346\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3953 - acc: 0.8374\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3945 - acc: 0.8362\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3950 - acc: 0.8368\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3947 - acc: 0.8372\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3942 - acc: 0.8364\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3948 - acc: 0.8369\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3939 - acc: 0.8356\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3945 - acc: 0.8362\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3942 - acc: 0.8383\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3944 - acc: 0.8378\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3939 - acc: 0.8381\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3930 - acc: 0.8375\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3926 - acc: 0.8378\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3933 - acc: 0.8360\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3923 - acc: 0.8393\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3910 - acc: 0.8376\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3902 - acc: 0.8407\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3887 - acc: 0.8397\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3859 - acc: 0.8379\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3830 - acc: 0.8386\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3816 - acc: 0.8386\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3809 - acc: 0.8387\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3792 - acc: 0.8390\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3783 - acc: 0.8375\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3781 - acc: 0.8382\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3763 - acc: 0.8378\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3757 - acc: 0.8362\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 127us/step - loss: 0.3752 - acc: 0.8397\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3746 - acc: 0.8412\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3748 - acc: 0.8392\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3745 - acc: 0.8406\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3738 - acc: 0.8415\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3737 - acc: 0.8412\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3735 - acc: 0.8390\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3726 - acc: 0.8404\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3727 - acc: 0.8406\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3725 - acc: 0.8422\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 162us/step - loss: 0.3727 - acc: 0.8412\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.3723 - acc: 0.8419\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 153us/step - loss: 0.3722 - acc: 0.8417\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3716 - acc: 0.8411\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3720 - acc: 0.8401\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3720 - acc: 0.8407\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3711 - acc: 0.8428\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3713 - acc: 0.8429\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3714 - acc: 0.8412\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3718 - acc: 0.8414\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3715 - acc: 0.8419\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3700 - acc: 0.8408\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3705 - acc: 0.8428\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3706 - acc: 0.8415\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3705 - acc: 0.8424\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3703 - acc: 0.8414\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3699 - acc: 0.8412\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3705 - acc: 0.8415\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3698 - acc: 0.8407\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3698 - acc: 0.8393\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3689 - acc: 0.8422\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3698 - acc: 0.8421\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3697 - acc: 0.8417\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3696 - acc: 0.8415\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3689 - acc: 0.8408\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3692 - acc: 0.8443\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3682 - acc: 0.8428\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3688 - acc: 0.8421\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3679 - acc: 0.8447\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3686 - acc: 0.8437\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3677 - acc: 0.8453\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3668 - acc: 0.8449\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3667 - acc: 0.8447\n",
            "800/800 [==============================] - 0s 236us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 228us/step - loss: 0.4912 - acc: 0.7961\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4201 - acc: 0.7969\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 126us/step - loss: 0.4108 - acc: 0.7969\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.4014 - acc: 0.8233\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3931 - acc: 0.8269\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3860 - acc: 0.8294\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3808 - acc: 0.8350\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3757 - acc: 0.8431\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3721 - acc: 0.8479\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 130us/step - loss: 0.3695 - acc: 0.8496\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 128us/step - loss: 0.3667 - acc: 0.8497\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3645 - acc: 0.8522\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 129us/step - loss: 0.3623 - acc: 0.8532\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3613 - acc: 0.8543\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3600 - acc: 0.8506\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3595 - acc: 0.8543\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3587 - acc: 0.8537\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3582 - acc: 0.8544\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3575 - acc: 0.8551\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3563 - acc: 0.8539\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3560 - acc: 0.8549\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3555 - acc: 0.8557\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3549 - acc: 0.8556\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3549 - acc: 0.8544\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3540 - acc: 0.8543\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3541 - acc: 0.8539\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3530 - acc: 0.8558\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3525 - acc: 0.8564\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3519 - acc: 0.8569\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3521 - acc: 0.8568\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3518 - acc: 0.8572\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3512 - acc: 0.8565\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3518 - acc: 0.8562\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3510 - acc: 0.8569\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3504 - acc: 0.8558\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3501 - acc: 0.8556\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3510 - acc: 0.8554\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3488 - acc: 0.8572\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3501 - acc: 0.8596\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 162us/step - loss: 0.3494 - acc: 0.8565\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3492 - acc: 0.8585\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3481 - acc: 0.8586\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3482 - acc: 0.8587\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3486 - acc: 0.8574\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3473 - acc: 0.8596\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3479 - acc: 0.8568\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3477 - acc: 0.8568\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3474 - acc: 0.8585\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3479 - acc: 0.8565\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3478 - acc: 0.8593\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3481 - acc: 0.8587\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3478 - acc: 0.8601\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3473 - acc: 0.8594\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3473 - acc: 0.8576\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3473 - acc: 0.8587\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3467 - acc: 0.8582\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3464 - acc: 0.8585\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3462 - acc: 0.8576\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3462 - acc: 0.8606\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3456 - acc: 0.8593\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3464 - acc: 0.8558\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3459 - acc: 0.8594\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3465 - acc: 0.8575\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3466 - acc: 0.8586\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3458 - acc: 0.8587\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3460 - acc: 0.8582\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3460 - acc: 0.8578\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3451 - acc: 0.8597\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3445 - acc: 0.8622\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3445 - acc: 0.8614\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3457 - acc: 0.8582\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3462 - acc: 0.8585\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3452 - acc: 0.8592\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3454 - acc: 0.8589\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3456 - acc: 0.8592\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3459 - acc: 0.8565\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3454 - acc: 0.8593\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3451 - acc: 0.8572\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3453 - acc: 0.8586\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3457 - acc: 0.8592\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3453 - acc: 0.8603\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3456 - acc: 0.8579\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3455 - acc: 0.8576\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3459 - acc: 0.8594\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3449 - acc: 0.8606\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3449 - acc: 0.8594\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3459 - acc: 0.8579\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3445 - acc: 0.8579\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3460 - acc: 0.8594\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3450 - acc: 0.8596\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3452 - acc: 0.8586\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3445 - acc: 0.8585\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3448 - acc: 0.8601\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3454 - acc: 0.8586\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3446 - acc: 0.8603\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3454 - acc: 0.8600\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3446 - acc: 0.8593\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3446 - acc: 0.8586\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3443 - acc: 0.8592\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3442 - acc: 0.8603\n",
            "800/800 [==============================] - 0s 255us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 1s 208us/step - loss: 0.4896 - acc: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4300 - acc: 0.7962\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4248 - acc: 0.7962\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4211 - acc: 0.8037\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4177 - acc: 0.8200\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4153 - acc: 0.8260\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4132 - acc: 0.8281\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4121 - acc: 0.8322\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4105 - acc: 0.8332\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 149us/step - loss: 0.4095 - acc: 0.8335\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 150us/step - loss: 0.4086 - acc: 0.8331\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 157us/step - loss: 0.4075 - acc: 0.8339\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.4072 - acc: 0.8346\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.4062 - acc: 0.8346\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.4058 - acc: 0.8329\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4056 - acc: 0.8343\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4049 - acc: 0.8351\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4043 - acc: 0.8346\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4039 - acc: 0.8354\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4038 - acc: 0.8351\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4032 - acc: 0.8344\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4028 - acc: 0.8357\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4029 - acc: 0.8358\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4025 - acc: 0.8356\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4017 - acc: 0.8353\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4014 - acc: 0.8365\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.4017 - acc: 0.8361\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4008 - acc: 0.8357\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.4002 - acc: 0.8362\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4011 - acc: 0.8350\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4004 - acc: 0.8343\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4003 - acc: 0.8351\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4005 - acc: 0.8378\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4000 - acc: 0.8364\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3997 - acc: 0.8351\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3993 - acc: 0.8358\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3992 - acc: 0.8349\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3990 - acc: 0.8356\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3989 - acc: 0.8344\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3994 - acc: 0.8369\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3993 - acc: 0.8362\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3991 - acc: 0.8371\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3988 - acc: 0.8347\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3986 - acc: 0.8374\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3988 - acc: 0.8360\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3986 - acc: 0.8362\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3983 - acc: 0.8347\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3985 - acc: 0.8368\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3986 - acc: 0.8367\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3986 - acc: 0.8342\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3984 - acc: 0.8361\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3985 - acc: 0.8357\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3982 - acc: 0.8361\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3985 - acc: 0.8362\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3985 - acc: 0.8347\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3982 - acc: 0.8362\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3982 - acc: 0.8364\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3983 - acc: 0.8360\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3987 - acc: 0.8367\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3981 - acc: 0.8372\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3980 - acc: 0.8358\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3982 - acc: 0.8372\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3979 - acc: 0.8356\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3978 - acc: 0.8362\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3975 - acc: 0.8353\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3982 - acc: 0.8372\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3974 - acc: 0.8360\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3982 - acc: 0.8371\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3982 - acc: 0.8361\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3984 - acc: 0.8375\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3977 - acc: 0.8358\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3978 - acc: 0.8367\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3972 - acc: 0.8339\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3979 - acc: 0.8375\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3977 - acc: 0.8369\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3977 - acc: 0.8361\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3979 - acc: 0.8362\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3977 - acc: 0.8371\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3975 - acc: 0.8361\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3977 - acc: 0.8371\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3975 - acc: 0.8371\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3978 - acc: 0.8339\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3975 - acc: 0.8361\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3976 - acc: 0.8368\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3978 - acc: 0.8362\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3976 - acc: 0.8360\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3971 - acc: 0.8362\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3976 - acc: 0.8362\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3973 - acc: 0.8360\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3978 - acc: 0.8378\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3978 - acc: 0.8372\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3972 - acc: 0.8376\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3970 - acc: 0.8353\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3978 - acc: 0.8371\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3973 - acc: 0.8365\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3974 - acc: 0.8367\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3972 - acc: 0.8354\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3977 - acc: 0.8369\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3972 - acc: 0.8358\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3973 - acc: 0.8353\n",
            "800/800 [==============================] - 0s 317us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 223us/step - loss: 0.4811 - acc: 0.7953\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.4141 - acc: 0.7957\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.4027 - acc: 0.8112\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3924 - acc: 0.8300\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3843 - acc: 0.8321\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3772 - acc: 0.8361\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3722 - acc: 0.8450\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3679 - acc: 0.8489\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3645 - acc: 0.8496\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3612 - acc: 0.8526\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3600 - acc: 0.8524\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3575 - acc: 0.8550\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3561 - acc: 0.8569\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3547 - acc: 0.8562\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3542 - acc: 0.8547\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3539 - acc: 0.8569\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3521 - acc: 0.8578\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3513 - acc: 0.8578\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 161us/step - loss: 0.3505 - acc: 0.8590\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3504 - acc: 0.8569\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3495 - acc: 0.8597\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3495 - acc: 0.8601\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3484 - acc: 0.8599\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3486 - acc: 0.8579\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3479 - acc: 0.8615\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3476 - acc: 0.8581\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3476 - acc: 0.8604\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3477 - acc: 0.8608\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3469 - acc: 0.8587\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3471 - acc: 0.8612\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3460 - acc: 0.8597\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3458 - acc: 0.8628\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3454 - acc: 0.8603\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3448 - acc: 0.8628\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3457 - acc: 0.8611\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3451 - acc: 0.8601\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3454 - acc: 0.8594\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3442 - acc: 0.8601\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3452 - acc: 0.8606\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3440 - acc: 0.8612\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3430 - acc: 0.8600\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3432 - acc: 0.8611\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3439 - acc: 0.8618\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 132us/step - loss: 0.3426 - acc: 0.8618\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3431 - acc: 0.8611\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3432 - acc: 0.8589\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3427 - acc: 0.8622\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3426 - acc: 0.8618\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3423 - acc: 0.8611\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 131us/step - loss: 0.3418 - acc: 0.8635\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3417 - acc: 0.8608\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3414 - acc: 0.8614\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3422 - acc: 0.8621\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3406 - acc: 0.8621\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3423 - acc: 0.8626\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3416 - acc: 0.8615\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3409 - acc: 0.8642\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3413 - acc: 0.8615\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3418 - acc: 0.8599\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3410 - acc: 0.8617\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3409 - acc: 0.8611\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3412 - acc: 0.8607\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3399 - acc: 0.8656\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3406 - acc: 0.8636\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3407 - acc: 0.8636\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3408 - acc: 0.8611\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3402 - acc: 0.8601\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3404 - acc: 0.8618\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3397 - acc: 0.8628\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3404 - acc: 0.8611\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3396 - acc: 0.8621\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3408 - acc: 0.8624\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3407 - acc: 0.8626\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 155us/step - loss: 0.3407 - acc: 0.8621\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 157us/step - loss: 0.3402 - acc: 0.8606\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 171us/step - loss: 0.3400 - acc: 0.8614\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3388 - acc: 0.8646\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3396 - acc: 0.8603\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3400 - acc: 0.8617\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3385 - acc: 0.8643\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3386 - acc: 0.8625\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3397 - acc: 0.8636\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3393 - acc: 0.8624\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3399 - acc: 0.8617\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3397 - acc: 0.8622\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3386 - acc: 0.8633\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3397 - acc: 0.8610\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3383 - acc: 0.8649\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3391 - acc: 0.8633\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3389 - acc: 0.8629\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3388 - acc: 0.8646\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3392 - acc: 0.8604\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3387 - acc: 0.8615\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3395 - acc: 0.8611\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.3382 - acc: 0.8614\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3388 - acc: 0.8628\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 133us/step - loss: 0.3379 - acc: 0.8632\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.3379 - acc: 0.8607\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3384 - acc: 0.8619\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3386 - acc: 0.8622\n",
            "800/800 [==============================] - 0s 327us/step\n",
            "Epoch 1/100\n",
            "7200/7200 [==============================] - 2s 227us/step - loss: 0.4904 - acc: 0.7960\n",
            "Epoch 2/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4327 - acc: 0.7961\n",
            "Epoch 3/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4302 - acc: 0.7961\n",
            "Epoch 4/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4267 - acc: 0.7961\n",
            "Epoch 5/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4233 - acc: 0.8092\n",
            "Epoch 6/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4205 - acc: 0.8181\n",
            "Epoch 7/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4189 - acc: 0.8247\n",
            "Epoch 8/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4169 - acc: 0.8276\n",
            "Epoch 9/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4157 - acc: 0.8293\n",
            "Epoch 10/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4146 - acc: 0.8303\n",
            "Epoch 11/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4139 - acc: 0.8315\n",
            "Epoch 12/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4126 - acc: 0.8325\n",
            "Epoch 13/100\n",
            "7200/7200 [==============================] - 1s 135us/step - loss: 0.4117 - acc: 0.8326\n",
            "Epoch 14/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4103 - acc: 0.8335\n",
            "Epoch 15/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.4101 - acc: 0.8326\n",
            "Epoch 16/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.4098 - acc: 0.8349\n",
            "Epoch 17/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4093 - acc: 0.8326\n",
            "Epoch 18/100\n",
            "7200/7200 [==============================] - 1s 134us/step - loss: 0.4086 - acc: 0.8349\n",
            "Epoch 19/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4078 - acc: 0.8321\n",
            "Epoch 20/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4068 - acc: 0.8329\n",
            "Epoch 21/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.4061 - acc: 0.8347\n",
            "Epoch 22/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.4055 - acc: 0.8336\n",
            "Epoch 23/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4043 - acc: 0.8353\n",
            "Epoch 24/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.4041 - acc: 0.8354\n",
            "Epoch 25/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4032 - acc: 0.8339\n",
            "Epoch 26/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.4022 - acc: 0.8343\n",
            "Epoch 27/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.4016 - acc: 0.8357\n",
            "Epoch 28/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.4009 - acc: 0.8346\n",
            "Epoch 29/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4013 - acc: 0.8340\n",
            "Epoch 30/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.4003 - acc: 0.8337\n",
            "Epoch 31/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.4002 - acc: 0.8358\n",
            "Epoch 32/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3996 - acc: 0.8356\n",
            "Epoch 33/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3995 - acc: 0.8349\n",
            "Epoch 34/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3992 - acc: 0.8350\n",
            "Epoch 35/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3987 - acc: 0.8340\n",
            "Epoch 36/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3988 - acc: 0.8346\n",
            "Epoch 37/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3986 - acc: 0.8354\n",
            "Epoch 38/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3985 - acc: 0.8354\n",
            "Epoch 39/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3979 - acc: 0.8346\n",
            "Epoch 40/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3983 - acc: 0.8358\n",
            "Epoch 41/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3984 - acc: 0.8360\n",
            "Epoch 42/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3975 - acc: 0.8368\n",
            "Epoch 43/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3975 - acc: 0.8368\n",
            "Epoch 44/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3968 - acc: 0.8362\n",
            "Epoch 45/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3977 - acc: 0.8344\n",
            "Epoch 46/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3974 - acc: 0.8350\n",
            "Epoch 47/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3972 - acc: 0.8344\n",
            "Epoch 48/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3976 - acc: 0.8337\n",
            "Epoch 49/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3969 - acc: 0.8344\n",
            "Epoch 50/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3964 - acc: 0.8365\n",
            "Epoch 51/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3973 - acc: 0.8346\n",
            "Epoch 52/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3964 - acc: 0.8346\n",
            "Epoch 53/100\n",
            "7200/7200 [==============================] - 1s 147us/step - loss: 0.3969 - acc: 0.8337\n",
            "Epoch 54/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3973 - acc: 0.8337\n",
            "Epoch 55/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3967 - acc: 0.8340\n",
            "Epoch 56/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3964 - acc: 0.8346\n",
            "Epoch 57/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3972 - acc: 0.8354\n",
            "Epoch 58/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3964 - acc: 0.8365\n",
            "Epoch 59/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3965 - acc: 0.8336\n",
            "Epoch 60/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3967 - acc: 0.8362\n",
            "Epoch 61/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3972 - acc: 0.8357\n",
            "Epoch 62/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3960 - acc: 0.8365\n",
            "Epoch 63/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3968 - acc: 0.8350\n",
            "Epoch 64/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3962 - acc: 0.8346\n",
            "Epoch 65/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3958 - acc: 0.8354\n",
            "Epoch 66/100\n",
            "7200/7200 [==============================] - 1s 138us/step - loss: 0.3958 - acc: 0.8356\n",
            "Epoch 67/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3958 - acc: 0.8358\n",
            "Epoch 68/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3957 - acc: 0.8361\n",
            "Epoch 69/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3962 - acc: 0.8340\n",
            "Epoch 70/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3956 - acc: 0.8337\n",
            "Epoch 71/100\n",
            "7200/7200 [==============================] - 1s 136us/step - loss: 0.3957 - acc: 0.8353\n",
            "Epoch 72/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3952 - acc: 0.8344\n",
            "Epoch 73/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3957 - acc: 0.8342\n",
            "Epoch 74/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3961 - acc: 0.8368\n",
            "Epoch 75/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3954 - acc: 0.8361\n",
            "Epoch 76/100\n",
            "7200/7200 [==============================] - 1s 137us/step - loss: 0.3957 - acc: 0.8351\n",
            "Epoch 77/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3959 - acc: 0.8349\n",
            "Epoch 78/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3958 - acc: 0.8350\n",
            "Epoch 79/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3952 - acc: 0.8350\n",
            "Epoch 80/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3959 - acc: 0.8351\n",
            "Epoch 81/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3945 - acc: 0.8364\n",
            "Epoch 82/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3961 - acc: 0.8353\n",
            "Epoch 83/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3954 - acc: 0.8333\n",
            "Epoch 84/100\n",
            "7200/7200 [==============================] - 1s 148us/step - loss: 0.3951 - acc: 0.8357\n",
            "Epoch 85/100\n",
            "7200/7200 [==============================] - 1s 151us/step - loss: 0.3958 - acc: 0.8343\n",
            "Epoch 86/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3958 - acc: 0.8343\n",
            "Epoch 87/100\n",
            "7200/7200 [==============================] - 1s 154us/step - loss: 0.3960 - acc: 0.8343\n",
            "Epoch 88/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3951 - acc: 0.8340\n",
            "Epoch 89/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3958 - acc: 0.8350\n",
            "Epoch 90/100\n",
            "7200/7200 [==============================] - 1s 139us/step - loss: 0.3958 - acc: 0.8356\n",
            "Epoch 91/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3951 - acc: 0.8357\n",
            "Epoch 92/100\n",
            "7200/7200 [==============================] - 1s 146us/step - loss: 0.3953 - acc: 0.8353\n",
            "Epoch 93/100\n",
            "7200/7200 [==============================] - 1s 143us/step - loss: 0.3956 - acc: 0.8362\n",
            "Epoch 94/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3960 - acc: 0.8333\n",
            "Epoch 95/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3949 - acc: 0.8344\n",
            "Epoch 96/100\n",
            "7200/7200 [==============================] - 1s 144us/step - loss: 0.3948 - acc: 0.8351\n",
            "Epoch 97/100\n",
            "7200/7200 [==============================] - 1s 140us/step - loss: 0.3951 - acc: 0.8350\n",
            "Epoch 98/100\n",
            "7200/7200 [==============================] - 1s 145us/step - loss: 0.3949 - acc: 0.8346\n",
            "Epoch 99/100\n",
            "7200/7200 [==============================] - 1s 141us/step - loss: 0.3950 - acc: 0.8362\n",
            "Epoch 100/100\n",
            "7200/7200 [==============================] - 1s 142us/step - loss: 0.3949 - acc: 0.8358\n",
            "800/800 [==============================] - 0s 369us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZSJ8dbSgGuS",
        "colab_type": "code",
        "outputId": "ca8f7e8a-e53a-468c-c8c7-6a5b811b97bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(accuracies)\n",
        "print (mean)\n",
        "print (variance)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.84124999 0.825      0.83875    0.84499999 0.85374999 0.84374999\n",
            " 0.86624999 0.82874999 0.83624999 0.83999999]\n",
            "0.8418749939650297\n",
            "0.011183832129563875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hG5x3DB7wfN",
        "colab_type": "text"
      },
      "source": [
        "# 6. Improving ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUL0Dyyb752e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## improving by drop out reguralization "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3q09waCl8SHE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dropout Regularization to reduce overfitting if needed\n",
        "# by importing Dropout, and add classifier.add(Dropout(p=0.1))\n",
        "# but in this case, i'm not gonna use Dropout because the accuracy is good\n",
        "# and the model is not overfitting. \n",
        "\n",
        "#import libraries\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "\n",
        "def build_classifier(optimizer):\n",
        "    classifier = Sequential()\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu', input_dim = 11))\n",
        "    classifier.add(Dropout(p=0.1))\n",
        "    classifier.add(Dense(units = 6, kernel_initializer = 'uniform', activation = 'relu'))\n",
        "    classifier.add(Dropout(p=0.1))\n",
        "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
        "    classifier.add(Dropout(p=0.1))\n",
        "    classifier.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "parameters = {'batch_size': [25, 32],\n",
        "              'epochs': [100, 500],\n",
        "              'optimizer': ['adam', 'rmsprop']}\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 10)\n",
        "grid_search = grid_search.fit(X_train, y_train)\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5leThe7kKI",
        "colab_type": "text"
      },
      "source": [
        "# 7. Tunning ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9hW97vWC8kh",
        "colab_type": "text"
      },
      "source": [
        "Find it in the other ipynb. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MY3DP0GZhYQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}